---
layout: mechanics
title: Теория Массового Обслуживания
order: 100
---
<div class="chapter_quote"><p>
Удовольствие от инжиниринга - это найти прямую линию на графике логарифма в квадрате.
<br/>
—Томас Кёниг
</p></div>


Теория массового обслуживания позволяет разобраться почему традиционная разработка чрезмерно медленная - и что с этим делать. В крупномасштабной разработке распространено, что "одна" фича (до разделения) может быть ошеломляюще гигантской. В таких областях, особенно хорошо заметно, что большие партии и длинные очереди действительно существуют и какие проблемы они вызывают. Сложно решить проблему, о существовании которой вы не знаете. И теория массового обслуживания указывает на некоторые способы для улучшений. Этот инструмент мышления особенно релевантен для крупных масштабов, поскольку большие, меняющиеся партии работы --- столь распространенные в традиционной модели --- имеют *нелинейное воздействие* на время цикла --- они *действительно* могут всё испортить,

<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-1.jpg" alt="queueing-1.jpg">
  <figcaption>Эта система имеет нелинейную динамику!</figcaption>
</figure>

Интересное несоответствие: Теория массового обслуживания --- математический анализ того как *вещи* двигаются сквозь систему с очередями --- была разработана, чтобы понимать и улучшать пропускную способность в телекоммуникационных системах --- системах с большой вариативностью и хаотичностью близкой к продуктовой разработке. Как следствие, телеком инженеры понимают основные идеи. Но по-прежнему, люди, занимающиеся развитием телеком инфраструктуры (телеком - это область больших продуктов) редко замечают, что *это применимо к их системе*, чтобы сократить среднее время цикла в их производственном процессе.

Люди из Тойота изучают статистическую вариацию и влияние теории массового обслуживания; это отражается в *выравнивающем* принципе бережливого подхода, который уменьшает вариативность и в целом в фокусе бережливого подхода на уменьшении размера партии и времени цикла прохождения *потока*.

Прежде чем погружаться в тему, отметим, что бережливый подход иногда описывается как концентрация на *меньших размерах партии*, *более коротких очередях*, и *сокращении времени цикла*. Быстрая поставка ценности. Бережливый подход существенно больше этого --- его столпы - *уважение к людям* и *непрерывное улучшение* которые опираются на основы в виде *руководителей-учителей в бережливом мышлении*. **Управление очередями (ограничение НЗР, ...) эффективная практика, но это лишь инструмент, далекий от глубокой сущности бережливого мышления.**

Как станет очевидно, LeSS поддерживает управленческие последствия теории массового обслуживания.

##  Миф Закона Литтла

Прежде чем дальше погружаться в теорию массового обслуживания, несколько слов о широко распространённом мифе, относящемся к теории массового обслуживания, распространённом в сообществах гибкой разработки и бережливого подхода (и даже в нескольких подходах к масштабированию), который следует незамедлительно прояснить. [Закон Литтла](http://web.mit.edu/sgraves/www/papers/Little's%20Law-Published.pdf) доказывает, что *уменьшение уровня НЗР (WIP) уменьшает среднее время цикла*. О, если бы это было так! К сожалению, доказательство Литтла зависит от ряда условий/предположений, которые должны соблюдаться для того, чтобы динамика оставалась положительной. И, к сожалению, эти условия никак не гарантируются или даже не являются как-правило-истинными в областях с высокой степенью изменчивости, таких как разработка программного обеспечения. Наивность продвижения или обоснования Закона Литтла в разработке программного обеспечения хорошо разобрана в анализе Даниэля Ваканти (Daniel Vacanti), названном [Ошибка Литтла] ([Little's Flaw]) (http://vimeo.com/52683659)


**Уменьшение уровня НЗР - достойная цель и значимо в LeSS. НЗР - это одна из потерь в бережливом мышлении, потому что это, помимо прочих проблем, задерживает возврат инвестиций, скрывает дефекты, уменьшает прозрачность. И уменьшение уровня НЗР выявляет недостатки. Но, к сожалению, в разработке программного обеспечения нет гарантии, что уменьшение НЗР автоматически уменьшит среднее время цикла.**
{: .box_top_bottom }

## Конкурировать за счёт Укорачивания Времени Цикла

Бережливая организация разрабатывающая продукты сосредоточена на *пропускной способности при поставке ценности в стабильных циклах за кратчайшее возможное время*, она сосредоточена прежде всего на *пропускной способности*, а не на занятости людей. Люди из Тойота, прародители бережливого мышления, являются мастерами во всё большем и большем ускорении (укорачивании) времени цикла **без перегрузки людей**.

Какие есть некоторые процессные циклы или что есть время цикла в продуктовой разработке?

* "от идеи до прибыли" за один релиз
* "от идеи до готовности" в одной фиче
* время до потенциальной готовности к поставке; как часто вы можете поставлять?
* время компиляции (для всего программного обеспечения)
* время от "готово к пилоту" до поставки
* время развертывания для тестирования (на интегрированном оборудовании)
* время на анализ и проектирование
{: .two_columns .box_top_bottom}

Ключевые показатели эффективности (КПЭ) в бережливом подходе *не* сосредоточены на утилизации или занятости рабочих, выполняющих вышеописанные процессы. Скорее, *КПЭ бережливого подхода фокусируются больше на пропускной способности и времени цикла*.

Тем не менее, предупреждение: Измерение обычно приводит к дисфункции или к попыткам 'обыграть' систему путем локальной оптимизации для того, чтобы создать видимость, как будто достигаются хорошие показатели. [[Austin96]](http://www.amazon.com/Measuring-Managing-Performance-Organizations-Dorset-ebook/dp/B00DY3KQX6/ref=sr_1_1?ie=UTF8&qid=1413596674&sr=8-1&keywords=measuring+and+managing+performance+in+organizations). Это особенно справедливо для 'низкоуровневых' процессных циклов. Показатели времени цикла более высокого уровня, такие как время цикла до потенциальной готовности к поставке и "от заказа до прибыли" или "от заказа до поставки" (наиболее существенные показатели времени цикла), являются более актуальными.

Что бы могла значить для вас возможность поставлять в *два или четыре раза быстрее* в *устойчивом темпе* без перегрузки людей? И с другой стороны, какова стоимость задержки?

Рассмотрите преимущества быстрой доставки с точки зрения жизненного цикла, полученных возможностей, реакции на конкуренцию и инноваций. Для большинства компаний---не для всех---это будет *выдающееся* преимущество.

**В два раза быстрее - это не в два раза дешевле**{: style="color: #1997C0"}---Когда люди слышат "в два раза быстрее" они возможно думают: "В два раза больше продуктов, функциональностей или релизов---вдвое эффективнее." Но здесь могут скрываться **операционные издержки**, накладные расходы в каждом цикле. Более частая поставка может увеличить расходы на тестирование или установку---или нет, как будет видно далее.

**В два раза быстрее - это не в два раза дороже**{: style="color: #1997C0"}---Не торопитесь убирать свои таблицы для анализа операционных расходов. Существует тонкая связь между временем цикла, операционными расходами и эффективностью, как вскоре будет прояснено---секрет, стоящий за впечатляющей эффективностью Toyota и других предприятий, использующих бережливое мышление ...

**Управление очередями**{: style="color: #1997C0"}---существует множество стратегий, нацеленных на уменьшение времени цикла; приверженцы и бережливого производства и практики гибкой разработки предлагают нам рог изобилия различных практичных средств. Один из таких инструментов является темой настоящего раздела---управление очередями.

##Управление Очередями для Уменьшения Времени Цикла

"*Очереди существуют только в производстве, так что теория массового обслуживания и управление очередями неприменимы к продуктовой разработке*." Это распространенное заблуждение. Как упоминалось ранее, теория массового обслуживания зародилась не в производстве, а в исследованиях операций для повышения пропускной способности в телекоммуникационных системах с высокой вариативностью. Тем не менее, многие группы разработки---особенно те, которые внедряют практики гибкой разработки или бережливого мышления---приняли управление очередью, основанное на понимании теории массового обслуживания как для *разработки продуктов*, так и для *управления портфелем*. Авторы одного исследования в МТИ (MIT, Массачусетский технологический институт) и Стэнфордском университете, пришли к следующему выводу:

> Бизнес подразделения, которые приняли этот подход [управление очередями для продуктового портфеля и управления продуктами] уменьшили среднее время разработки на 30-50% [[AMNS96]](http://www-bcf.usc.edu/~padler/research/HBR_prod_dev_proc.pdf)

### Очереди в Разработке Продукта и Управлении Портфелем

Примеры очередей в разработке и управлении портфелем?

* продукты или проекты в портфеле
* новые функциональности для одного продукта
* подробные спецификации требований, ожидающие проектирования
* проектные документы, ожидающие разработки
* код ожидающий тестирования
* код одного разработчика ожидающий интеграции с другими разработчиками
* большие компоненты, ожидающие интеграции
* большие компоненты и системы ожидающие тестирования
{: .two_columns .box_top_bottom}



В традиционной последовательной разработке существует множество очередей с частично сделанной работой, известные как не-завершенная-работа **очереди НЗР **; например, документы со спецификацией, ожидающие начала программирования или код, ожидающий начала тестирования.

В добавлении к *очередям НЗР* , существуют **ограниченные-ресурсы** или **очереди разделяемых-ресурсов**, такие как бэклог запросов на использование дорогостоящей тестовой лаборатории или оборудования для тестирования.

### Очереди Являются Проблемой

Во-первых, если не существует очередей---и нет многозадачности, которая искуственно создаёт видимость, что очередь устранена---тогда система двигается в направлении потока, принцип бережливого подхода и стремления к совершенству в том, что ценность поставляется без каких-либо задержек. Каждая очередь создаёт задержку, которая является препятствием для потока поставки ценности. Если говорить более конкретно, почему очереди являются проблемой?

#### Очереди НЗР

Очереди НЗР в разработке продуктов  редко рассматриваются как таковые по нескольким причинам; возможно главная среди них в том, что они как правило *незаметны* ---набор битов на диске компьютера. Но они действительно существуют---и что более важно, они создают проблемы. Почему?

Очереди НЗР (как и большинство очередей) *увеличивают среднее время цикла* и уменьшают поставку ценности и тем самым могут снизить общую прибыль.

В бережливом мышлении, очереди НЗР классифицируются как *потери* ---и, следовательно, должны быть устранены или сокращены---потому, что:

* Очереди НЗР имеют вышеупомянутое воздействие на время цикла.
* Очереди НЗР являются *частично-готовыми запасами* (спецификаций, кода, документации, ...) с вложением времени и денег, для которых ещё не произошло возврата инвестиций.
* Так же как и все запасы, очереди НЗР скрывают ошибки---и способствуют их распространению---поскольку груда запасов  ещё не была использована или проверена на следующем шаге процесса, чтобы проявить скрытые проблемы; например, большое количество ещё не-интегрированного кода.
* Одна история: Мы видели продуктовую группу, использующую традиционные подходы к разработке,  которая потратила около года, работая над функциональностью “завершение сделки”. Затем управление продуктом решило удалить её, потому что она поставила под угрозу весь релиз и рыночные условия изменились. Перепланирование заняло много недель. В целом, очереди НЗР *влияют на стоимость и способность реагировать на изменения* (удаления и добавления) потому, что: (1) время и деньги были потрачены на незавершенную удалённую работу которая не будет в конечном итоге реализована, или  (2) НЗР, связанная с удалёнными элементами, может быть тесно переплетена с другой функциональностью, или (3) новая функциональность, ожидающая добавления, может испытать отложенный запуск из-за высокого уровня текущей НЗР.
<br>

Как будет рассмотрено далее, существует тонкий, но потенциально очень мощный побочный эффект улучшения-систем, который может возникнуть в процессе устранения очередей НЗР.

#### Очереди Разделяемых-Ресурсов

В противоположность очередям НЗР (которые на первый взгляд не кажутся тем, чем являются), очереди разделяемых-ресурсов чаще всего **видятся как очереди**---и видятся как проблема. Они действительно заметно и болезненно замедляют людей, задерживают обратную связь и растягивают время цикла. *“Нам нужно протестировать свой новый код на том целевом принтере в тестовой лаборатории. Когда он будет свободен?”*

#### План А: Ликвидация (а не управление) Очередями

В итоге суть такова, что (как правило) *очереди являются проблемой*. Исходя из этого, вы можете сделать поспешный вывод, что первая линия обороны против этой проблемы - *уменьшить объёмы партий и размер очереди* , потому, что таковы классические стратегии управления-очередью. Однако существует решение, позволяющее "разрубить [Гордиев Узел](https://en.wikipedia.org/wiki/Gordian_Knot)", которое следует рассмотреть первым...

В оставшейся части этой главы мы, несомненно, рассмотрим уменьшение времени цикла путём управления размерами партий-и очередей-. Но вся эта стратегия управления должна быть *Планом Б*. Скорее, начать следует с *Плана А*:

**План А в исправлении проблемы очереди заключается в полном искоренении этой очереди, навсегда, изменив саму систему: организационную систему, систему разработки, инструменты, процессы, практики, политики, и т.п.**
{: .box_top_bottom }

Превзойдите границы мышления и сократите время цикла, изменив саму *систему* так, чтобы очереди больше не существовало---устраняя узкие места (bottleneck) и другие воздействия, являющиеся причинами очередей. Эти ограничения и очереди, которые они порождают, могут быть как созданы так и уничтожены самой природой системы разработки и её инструментами.

Предположим существующая система основывается на последовательной разработке с рабочими или группами одной-специализации/функции. В такой системе будут существовать очереди НЗР: Группа аналитиков передаёт пакеты рабочих спецификаций группе разработчиков, которая передаёт пакеты рабочего кода группе тестирования, которая передаёт код группе внедрения и эксплуатации.  Мерами, лежащими в *пределах-границ-мышления*. по улучшению с помощью управления очередями, является уменьшение лимитов НЗР и размеров очередей. Но такой подход имеет дело всего лишь со вторичными симптомами существующей системы.

Существует более фундаментальная альтернатива, которая может радикально улучшить время цикла: Откажитесь от существующей системы, от её узких мест и от очередей НЗР, которые они порождают. Если вы внедрите **кросс-функциональные продуктовые команды, которые поставляют полностью готовую функциональность** (включая аналитику, программирование и тестирование), без передачи работы другим группам и которые применяют автоматизированную **разработку через приёмочное тестирование** и **автоматизированную непрерывную поставку**, то вышеупомянутые очереди НЗР *исчезнут* благодаря переходу от последовательной к параллельной разработке.

Этот подход отражает видение, основанное на исправлении-корневых-причин в LeSS: Измените организационную структуру для решения ключевых проблем.


#### Фальшивая Ликвидация Очереди

Предположим вы заняты работой над элементом А, а элементы Б, В, Г  и Д находятся в вашей очереди. Фальшивым сокращением очереди было бы работать над *всеми* этими элементами в примерно одно и то же время---высокий уровень многозадачности и утилизации. Многозадачность считается одной из потерь в бережливом подходе, потому что, как мы вскоре увидим, теория массового обслуживания показывает, что это способствует *увеличению* среднего времени цикла,  а не его уменьшению. И этот фальшивый подход фактически увеличивает уровень НЗР, во имя его уменьшения! Плохая идея.

Не увеличивайте многозадачность или уровень утилизации для создания *иллюзии* что очередь была уменьшена и система была улучшена; скорее, улучшайте саму систему, чтобы узкие места и другие воздействия, которые создают очереди, были устранены.

#### План Б : Управляйте Очередями Когда Вы Не Можете Ликвидировать Их

Распространённые очереди НЗР могут быть ликвидированы переходом к LeSS с кросс-функциональными продуктовыми командами, применением разработки через приёмочное тестирование (A-TDD) и непрерывной поставки. Изгнанные и исчезнувшие благодаря Плану А---изменение самой системы. Это идеальное решение, рекомендованное в LeSS.

Однако по-прежнему очереди могут оставаться и остаются, такие, как:

* очереди разделяемых-ресурсов, таких, как тестовая лаборатория
* очередь запросов на новую функциональность Бэклоге Продукта
* очереди НЗР потому, что: (1) План А пока ещё не осуществим (глубокие изменения в больших группах требуют времени), или (2) инструменты и техники, такие как переход от ручного к полностью автоматизированному тестированию, пока слабы и улучшаются медленно

По какой бы причине очереди не оставались---и в конце концов, Бэклог Продукта останется всегда---вы можете улучшить средне время цикла благодаря Плану Б, управляя очередями:

**План Б: Для очередей, которые не могут искоренены, улучшайте среднее время цикла путём уменьшения объёмов партий в очередях, уменьшения лимитов НЗР и размеров очередей и стараясь делать все партии более-менее одинакового размера.**
{: .box_top_bottom }

В LeSS, меньший объём партии означает меньший рабочий пакет элементов или функциональности для разработки в Спринте. Выровненные по размеру партии подразумевают, что каждая такая порция работ оценивается примерно в одинаковое количество затрат.

Как конкретно применить это в LeSS? Это будет раскрыто чуть позже, а сначала,  погрузимся в область теории массового обслуживания...











## Теория Массового Обслуживания

Это могло бы потребовать тяжелой работы или какого-то нового подхода, но не нужно много теории для того, чтобы "управлять очередями” путём их *ликвидации*. С другой стороны, когда они должны существовать ни смотря ни на что, полезно знать как иметь с ними дело с помощью инструмента мышления теории массового обслуживания.

### Формальная Модель для Оценки Процессов

Вы можете принять за чистую монету, что очереди с меньшими партиями-функциональностей, одинакового размера улучшают среднее время цикла. Или нет. В любом случае, полезно знать, что эта рекомендация не основывается на чьём-либо мнении, а опирается на формальную математическую модель, которая может быть подтверждена. Некоторые аспекты процесса разработки *действительно* возможно аргументировать с помощью формальной модели. Например:

* *Гипотеза* : Наиболее верный способ - последовательная (‘водопадная’ или V-модель) разработка с передачей больших объёмов партий между специализированными функциональными группами.
* *Гипотеза* : Наиболее правильно для людей или групп - иметь высокие показатели утилизации и многозадачности на многих проектах в одно и то же время.
<br>

Понимание теории массового обслуживания, свободной от чьих-либо мнений, поможет выявить действительно ли эти гипотезы помогают уменьшить среднее время цикла.

Данная тема относительно проста; пример сценария, охватывающего ключевые аспекты ...

### Качества Стохастической Системы с Очередями

<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-1.jpg" alt="queueing-1.jpg">
  <figcaption>Эта система имеет нелинейную динамику!</figcaption>
</figure>

Рассмотрим Лос-Анджелес или Бангалор в час пик. Пока каким-то чудом здесь нет аварий и все полосы открыты. Поток плотный и медленный, но движется. Затем за короткий промежуток времени, происходят аварии на трёх различных основных четырёхполосных шоссе (всего двенадцать полос) и три линии закрываются---только девять линий остаются по-прежнему открытыми. Буум! Прежде чем вы успеете сказать: “Почему я не купил вертолёт?” на большей части города происходит *сдвиг фазы* в состояние *пробка*. Когда последствия аварий окончательно расчищены (в последующем промежутке от тридцати до шестидесяти минут), проходит *вечность*, прежде чем расчистится огромная накопленная очередь. Наблюдения:

* **Нелинейность**{: style="color: #1997C0"}---Когда шоссе загружено от нуля до пятидесяти процентов, оно плавно плывёт---практически нет задержек или очередей. Но междц пятьюдесятью и ста процентами, замедление становится заметным, начинают выстраиваться очереди. Связь загрузки шоссе с размером очереди не линейное, нет плавного линейного увеличения от нуля.
* **Задержки и перегрузка не начинается с 99.99% загрузки**{: style="color: #1997C0"}---Это *не* тот случай, когда всё на шоссе двигается быстро и плавно, до тех пор пока не достигнута 100-процентная загрузка машин на дороге. Напротив, всё замедляется и появляются пробки задолго до того как достигнута максимальная загрузка.
* **Расчистка очереди занимает больше времени чем её создание**{: style="color: #1997C0"}---сорокапятиминутный затор в Лос-Анджелесе в час пик создаёт очереди, расчистка которых занимает более сорока пяти минут.
* **Стохастичность, не детерминированность**{: style="color: #1997C0"}---Существует вариация и беспорядочность в вероятности (это **стохастическая** система): прибытия машин, времени устранения заторов, скорости выхода автомобилей из пробок.

Это стоит прояснить, если вы хотите разобраться в поведении системы, поскольку, судя по всему, все мы, люди, *не* имеем интуитивного понимания стохастических и нелинейных качеств систем с очередями. Наоборот, внутренний инстинкт говорит, что они детерминированы и ведут себя линейно. Этот ошибочный “здравый смысл” приводит к *ошибочному мышлению* при анализе проблем и управлении разработкой продуктов. Эти наблюдения---как и ошибки мышления---применимы также и к очередям НЗР  в традиционной продуктовой разработке и практически ко всем другим очередям.

Одна распространённая ошибка мышления в разработке продуктов заключается в том, что очереди, задержки и люди, которые их обслуживают, ведут себя как на Рисунке 1---это заблуждение “*задержки начинаются только тогда, когда шоссе заполнено на 100 процентов.* ” На самом деле задержки  начинают возникать на шоссе задолго до того, как оно заполнится на 100 процентов. Возможно вы начнёте наблюдать задержки при 60-процентной загрузке---а значит, более долгое среднее время цикла.


<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-4.png" alt="queueing-4.png">
  <figcaption>Рис. 1. Распространённый миф или ошибка мышления по поводу очередей в системах с вариативностью.</figcaption>
</figure>


Из-за заблуждения “*задержки начинаются только тогда, когда шоссе заполнено на 100 процентов,* ” возникает неправильный фокус на попытках улучшить время цикла путём *увеличения* утилизации ресурсов---заставляя людей, разрабатывающих продукт, быть более загруженными, как правило, за счёт увеличения многозадачности. *Это ошибка мышления, основанного на локальной-оптимизации.*

Что на самом деле происходит, когда кто-то увеличивает уровень утилизации инструментов или людей в системах с вариативностью?

В Xerox есть дорогие большие цифровые печатные прессы в тестовой лаборатории. Часто возникает очередь разделяемого-ресурса из запросов на тестирование на одном из этих устройств. Без понимания того, как на самом деле работают очереди (точнее, вера в то, что они работают как на Рис. 1) подход к управлению должен был бы заключаться в том, чтобы способствовать резервированию и утилизации этих дорогостоящих систем, близкой к 100 процентам. Но реальность такова, что повсюду существует *вариативность*---стохастическая система. Тесты поступают случайно, некоторые  быстро завершаются с ошибкой, выполнение некоторых занимает целую вечность, иногда ломается оборудование и тому подобное. *Такая же вариативность существует и в поведении людей и в очередях работы, которую они выполняют* .

<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-5.JPG" alt="queueing-5.JPG">
  <figcaption>Тестовая лаборатория в  Xerox с очередями разделяемых-ресурсов для оборудования.</figcaption>
</figure>

### Моделирование Базовой Системы с Очередями и Единичным-Поступлением  

Как ведут себя эти системы---в дорожном трафике, тестовых лабораториях, или в традиционной разработке, где люди сталкиваются с очередями НЗР? У вас уже сложилось понимание этого из истории о трафике. Математически, это поведение может быть моделировано в виде вариаций систем М/М. М/М означает, что  that the внутренний порядок поступления в очередь является Марковским, а также  порядок обработки элементов очереди тоже *Марковский*. Что такое Марковский: Простая концепция---некий случайный (стохастический) процесс, в котором состояние в будущем не может быть детерминировано на основании его прошлых состояний (см. [Цепь Маркова](https://ru.wikipedia.org/wiki/Цепь_Маркова) прим. переводчика); то есть, похоже на “беспорядочную реальность.”

Наиболее распространённую, базовую модель очереди можно обозначить так: М/М/1/*∞* ---она имеет один обработчик (например, один тестовый принтер или команду) и бесконечную очередь. (Очереди в разработке, как правило, не бесконечны, но это упрощение не повлияет на базовый паттерн поведения системы.)

Теперь становится интереснее ... Как в системе М/М/1/*∞*, соотносится время цикла и время обслуживания с загрузкой обработчика---будь то тестовый принтер или люди, работающие с очередями НЗР? График "Ожидание в базовых системах М/М/1/∞." показывает это [[Smith07]](http://www.amazon.com/Flexible-Product-Development-Building-Changing/dp/0787995843/ref=sr_1_1?ie=UTF8&qid=1413673423&sr=8-1&keywords=flexible+product+development).

На графике "Ожидание в базовых системах М/М/1/∞." показаны *примерные* значения, поскольку факторы имеют случайную вариативность, например:

* запросы поступают в разное время с разной интенсивностью
* усилия, необходимые на тесты или программирование, занимают разное время
* люди могут работать быстрее или медленнее, заболеть, работать дольше или меньше


<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-6.png" alt="queueing-6.png">
  <figcaption>Ожидание в базовых системах М/М/1/∞.</figcaption>
</figure>


Существенный момент, который следует осознать, заключается в том, что элемент (например, такой, как запрос нового требования) начнёт попадать в очередь, ожидая обслуживания, задолго до того, как люди будут загружены на 100 процентов. Также удивительно увидеть влияние увеличения загрузки людей на время цикла: *Когда загрузка возрастает, в системе с большой вариативностью, среднее время цикла ухудшается, не улучшается.* Это контринтуитивно для заурядного бухгалтера или консультанта по вопросам управления  который был обучен “улучшать продуктивность путём увеличения утилизации ресурсов.” Большинство из них не были знакомы с теорией массового обслуживания have---как понимать стохастическую систему с очередями (людей, выполняющих работу с вариативностью)---и поэтому демонстрируют распространённую ошибку мышления.


Именно эта изменчивость реальной жизни, в основном, и увеличивает размер очереди и время ожидания в разработке продуктов.
{: .box_top_bottom .text_centered_bold }


### Моделирование Пакетной Системы с Очередями  (Традиционная Разработка)

Становится *ещё более* интересно (если вы сможете в это поверить)...  Базовая система М/М/1/*∞* подразумевает, что элементы (на тестирование, анализ, разработку, ...) прибывают изолированно, по *одному*---что прибывающие элементы никогда не группируются (не объединяются в пакеты). Однако в традиционной разработке продуктов, пакеты работ *в действительности* прибывают большими, объёмными партиями, такими как набор требований или задач на тестирование  или большой партии кода, которая должна быть интегрирована. Или ‘единственное’, как предполагается, требование может быть получено в форме: «обработка сделок с деривативами на рынке Бразилии», но что по факту тоже является пакетом под-требований. Этот последний момент очень важно отметить, поскольку большое требование никогда *не* проходит через систему как один пакет требований, хотя "со стороны" это и может ошибочно казаться одним цельным пакетом требований.


“Одно большое требование само по себе является пакетом” - это критически важный момент который будет рассмотрен далее.
{: .box_top_bottom .text_centered_bold }


Итак, вместо более простой системы с единичным-поступлением по модели М/М/1/∞ (на вход поступают отдельные, атомарные элементы работы), рассмотрим систему М[x]/М/1/∞ (на вход которой поступают пакеты элементов). Эта модель является лучшей аналогией традиционной продуктовой разработке.

<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-7.png" alt="queueing-7.png">
  <figcaption>Ожидание в  системе М[x]/М/1/∞ - нечто cхожее с традиционной  разработкой с пакетами переменного размера.</figcaption>
</figure>


С первого раза, люди могут не осознать такого поразительного и кажущегося нелогичным влияния на их время цикла.

Следующая история поможет разобраться: Представим человека или команду, загруженных на текущий момент на 50 процентов, вы обычно даёте им по одному требованию небольшого размера время от времени, которые поступают с некоторой случайностью и могут несколько отличаться в размере. Предположим  что им потребуется *две недели* фактической работы, чтобы выполнить некое требование-X. И предположим, что это простая система с одиночным поступлением. В таблице ниже приведена аппроксимация типовой ситуации:

<table style="width:100%">
  <tr>
    <th>Поступление</th>
    <th>Утилизация</th>
    <th>Время в Очереди (Ожидания)</th>
    <th>Время Обработки (Обслуживания)</th>
    <th>Время Цикла</th>
    <th>Коэффициент ВремяЦикла/ВремяОбработки</th>
  </tr>
  <tr>
    <td>единичное поступление</td>
    <td>50%</td>
    <td>2 недели</td>
    <td>2 недели</td>
    <td>4 недели</td>
    <td>2</td>
  </tr>
</table>
<br>
<br>


Далее, наоборот, предположим что вы обычно даёте на 50 процентов загруженной команде существено бóльшие *пакеты* требований или по ‘одному’ гигантскому требованию, которые фактически включают в себя большой пакет под-требований; такие пакеты поступают с некой случайностью во времени и могут отличаться по размеру. Предположим, что непосредственно на обслуживание некоего пакета-X или одиночного требования уходит *двадцать недель*.

Основываясь на предыдущей таблице, вот какие значения некоторые люди прогнозировали бы для ситуации поступлением больших партий:

<table style="width:100%">
  <tr>
    <th>Поступление</th>
    <th>Утилизация</th>
    <th>Время в Очереди</th>
    <th>Время Обработки</th>
    <th>Время Цикла</th>
    <th>Коэффициент ВремяЦикла/ВремяОбработки</th>
  </tr>
  <tr>
    <td>единичное поступление</td>
    <td>50%</td>
    <td>2 недели</td>
    <td>2 недели</td>
    <td>4 недели</td>
    <td>2</td>
  </tr>
  <tr>
    <td>а если большая партия?</td>
    <td>50%</td>
    <td>20 недель</td>
    <td>20 недель</td>
    <td>40 недель</td>
    <td>2</td>
  </tr>
</table>
<br>
<br>

Предсказание, основанное на внутреннем ощущении *линейно* увеличивает воздействие на время цикла. В среднем в десять раз возросло количество работы "пропущенной" через систему, значит в десять раз должно возрасти время цикла. Четыре недели вместо сорока недель.

Но так это не работает, потому что в систему введено больше вариативности. Что же в таком случае происходит на самом деле?

При 50-процентной утилизации, коэффициент времени цикла-к-обслуживанию  на самом деле ‘5’ в примере  М[x]/М/1/∞. Это приблизительно соответствует следующей ситуации, сильно отличающейся от предыдущего предположения:


<table style="width:100%">
  <tr>
    <th>Поступление</th>
    <th>Утилизация</th>
    <th>Время в Очереди</th>
    <th>Время Обработки</th>
    <th>Время Цикла</th>
    <th>Коэффициент ВремяЦикла/ВремяОбработки</th>
  </tr>
  <tr>
    <td>единичное поступление</td>
    <td>50%</td>
    <td>2 недели</td>
    <td>2 недели</td>
    <td>4 недели</td>
    <td>2</td>
  </tr>
  <tr>
    <td>большая партия</td>
    <td>50%</td>
    <td>80 недель</td>
    <td>20 недель</td>
    <td>100 недель</td>
    <td>5</td>
  </tr>
</table>
<br>
<br>



So pushing for high utilization rates of workers in this situation with big batches of work is a recipe for... sloooow. The reality will be a super-linear increase in cycle time. This impact on delay and queue size defies our instinct because people are not used to analyzing stochastic systems with queues. One might think, “If I make the work package ten times bigger, it will take ten times as long to exit the system.” Do not count on it.
Всё стало *намного* хуже. Конечно, это некие усреднения и они не могут быть приняты ни для какого реального случая и эта модель является упрощённой абстракцией реальной продуктовой разработки. Но вот почему понимание---и действие в соответствии с этим пониманием---теории массового обслуживания применимо для крупно-масштабной разработки. Потому что большие системы часто связаны с масштабными требованиям, и большим количеством работы (разработка требований, тестирование, интеграция, ...) в больших партиях, прибывающих в случайное время, с работниками, утилизация (загрузка) которых ожидается  около 100%  на протяжении всего времени. Это может оказать невероятное влияние не среднее время цикла.

И эти задержки ещё более усугубляются в традиционной последовательной разработке, поскольку  существуют *серии* процессов с очередями НЗР перед ними; это усугубляет вариативность и добавляет больше негативного влияния на общее среднее время цикла. *Закон Распределения Вариативности* [[HS08]](http://www.amazon.com/Factory-Physics-Wallace-J-Hopp/dp/1577667395/ref=sr_1_1?ie=UTF8&qid=1413686585&sr=8-1&keywords=Factory+Physics) показывает, что худшее место для вариативности (в плане негативного воздействия на время цикла) - в самом начале многоступенчатой системы с очередями. Это как раз то, что происходит в традиционной разработке на первой фазе анализа требований с большими порциями спецификаций.

### Заключение

Итак, что мы узнали?

* разработка продуктов  - это стохастическая система с очередями; она нелинейна и не детерминирована
* поведение стохастической системы с очередями противоречит нашим инстинктивным, внутренним ощущениям
* размер партии, размеры требования и степень утилизации влияют на размер очереди и время цикла нелинейным, случайным способом, который не является очевидным---другими словами, пропускная способность  может *уменьшаться*
* размер очереди влияет на время цикла
* в изменчивой системе, высокая утилизация *увеличивает* время цикла и снижает пропускную способность---традиционный подход к управлению ресурсами здесь не помогает [[например, McGrath04]](http://www.amazon.com/Next-Generation-Product-Development-Productivity/dp/0071435123) и может, наоборот, усугубить ситуацию если сосредоточиться  на локальной оптимизации загрузки рабочих вместо пропускной способности системы
* система с вариативностью и серией процессов с очередями НЗР еще больше усугубляет задержку; эта ситуация характеризует традиционную последовательную разработку ПО
* высокая вариативность на входе многоступенчатой системы с очередями имеет наиболее пагубные последствия








## Скрытые Партии: Чутьё на Партии

Если вы печёте три вишнёвых пирога в одно и то-же время, то очевидно, что это партия из трёх пирогов. Но в разработке продуктов не всё так очевидно: Что в точности из себя представляет ‘одно’ требование? На каком-то уровне, “обработка сделок с облигациями и ценными бумагами” является одним требованием, но на другом уровне это также и *составное требование* или партия (пакет) под-требований которое может быть разделено. Нужно научиться распознавать такие скрытые партии.

![queueing-8.jpg](/img/queueing_theory/queueing-8.jpg)

Как мы увидели,  в системе с очередями, ведущей себя в соответствии с моделью М[x]/М/1/∞ и с высоким коэффициентом утилизации, большие партии переменного размера пагубно влияют на время цикла. И, так называемые, *одиночные* большие элементы с вариативностью также ухудшают время цикла, поскольку на самом деле за ними скрываются большие партии. Таким образом, выводы об управлении очередями в LeSS заключаются в следующем:

Чтобы уменьшить среднее время цикла, поддерживайте некоторое бездействие в системе (не допускайте "100% загрузки") и (со временем, постепенно) сокращайте все якобы ‘одиночные’ большие элементы (требования) в Бэклоге Продукта до небольших и примерно одинаковых по размеру элементов.
{: .box_top_bottom .text_centered_bold }









## Скрытые Очереди: Чутьё на Очереди

Когда люди приходят в Toyota, их учат иметь “Чутьё ("Нюх") на Потери.” Они учатся находить потери в тех вещах, которые ранее они не считали таковыми, таких как *запасы* ---например, очереди товара или деталей. После такого обучения, людям легко заметить очереди из *физических* вещей, и распознать это как проблему... Боже мой, да там *гигантская* груда всякого *Барахла* стоящего в очереди! Делаются ли какие-то деньги из этой кучи? Кто знает, есть ли там дефекты? Нужно ли объединить это с какими-то другими деталями, для того чтобы мы смогли поставить это? Действительно ли нам нужны ---и мы сможем сделать из этого деньги---*все без исключения* вещи в этой груде?

**Незаметные очереди**{: style="color: #1997C0"}---В традиционной разработке также существуют все виды очередей, но из-за того что они *незаметные*, они не видятся как очереди или не *ощущаются остро* как проблемы. Если вы бизнесмен, который инвестировал десять миллионов евро для создания гигантской груды частично сделанного *Барахла*, лежащего на полу, не приносящего никаких денег, вы пройдёте мимо него, *ощутите его* и тогда вы почувствуете всю боль и срочность, достаточную для того, чтобы заставить это двигаться. И тогда вы подумаете о том, что больше никогда не будете создавать такие большие груды частично сделанных вещей. Но люди в продуктовой разработке не видят и не ощущают настолько всю боль от их очередей.

Но всё же,  они  там *есть*. Очереди НЗР---информация, документация и биты на диске. Незаметные очереди. Люди из разработки продуктов нуждаются в хорошем уроке по “Чутью на Очереди”, чтобы они начали ощущать что происходит и вырабатывать ощущение срочности в отношении уменьшения размеров очередей.

**Визуальное управление для  осязаемых (материальных) очередей**{: style="color: #1997C0"}---Чтобы развить“Чутьё на Очереди” и внимательность , существует одна  практика в бережливом подходе *визуальное управление*, создание *физических* жетонов (не в компьютерной программе) для этих очередей. Например, популярная  практика -  представить все задачи в Спринте в виде бумажных карточек, которые располагаются на стене и перемещаются по мере выполнения задач. Аналогично для высокоприоритетных задач в Бэклоге Продукта. Эти *физические, ощутимые* карточки делают по-настоящему видимыми незаметные очереди которые скрыты где-то внутри компьютера. Сокрытие этой информации внутри компьютеров противоречит этому стремлению бережливого подхода визуального (физического) управления and тому как *люди*---с бессчётным количеством эпох эволюции вырабатывающие инстинкт работать с конкретными, ощутимыми вещами---нуждаются в  том чтобы *видеть и чувствовать осязаемые очереди* .


<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-9.JPG" alt="queueing-9.JPG">
  <figcaption>Визуальное управление (физические карточки) делает видимым незаметные очереди и НЗР.</figcaption>
</figure>







## Косвенные Преимущества Уменьшения Размеров Партий и Времени Цикла

“К чем беспокоиться? Наши клиенты не хотят обновлений каждые две недели, также как они не хотят получать только результаты под-требований вместо масштабных обновлений.”

Мы слышим такой вопрос регулярно от продуктовых групп и людей, приближенных к бизнесу. Они еще не оценили преимущества небольших партий в коротких циклах:

* *Общее* глобальное сокращение времени-релизного-цикла, которое может случиться благодаря ликвидации очередей и применению практик управления очередями, таким образом многие циклы в разработки становятся короче.
* Устранение **пакетной задержки**, когда одна небольшая новая функциональность неоправданно сдерживается из-за того, что она связанна с большой партией других требований. Устранение этого переводит вас на следующую ступень свободы, что позволяет поставлять меньший продукт раньше с выско-приоритетной функциональностью .
* Последнее, но при этом не менее важное,  существуют *косвенные* преимущества благодаря эффекту “*камни в озере* ”, описанному ниже.


### Косвенные Преимущества: Метафора о Камнях в Озере

Метафора из бережливого подхода: **камни в озере**. Глубина озера представляется в виде количества запасов, размеров партий, длины итерации, или времени цикла. Когда вода в озере высока (большие объёмы партий, или количество запасов, или длина итерации), многие подводные камни скрыты на дне озера. Эти камни представляют собой недостатки. Например, рассмотрим  восемнадцатимесячный цикл релиза с масштабным пакетом изменений; неэффективное тестирование, интеграция, плохое взаимодействие скрыты под "поверхностью" такого длинного цикла и такого огромного пакета требований. Но если бы мы работали с этой группой и попросили бы их: “Пожалуйста, создавайте готовый к поставке небольшой набор новой функциональности каждые две недели,” то все неэффективные практики неожиданно стали бы болезненно очевидными.


<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-10.jpg" alt="queueing-10.jpg">
  <figcaption>Уменьшение размеров партий (или времени цикла) обнажает скрытые недостатки.</figcaption>
</figure>



Говоря другими словами, *операционные затраты* (накладные расходы) из предыдущего цикла процесса становятся неприемлемыми. Эта боль затем станет позывом к улучшению, поскольку люди не смогут вынести повторения этого снова и снова, в каждом коротком цикле, и на самое деле это может быть просто недопустимо для целей итерации: оставаться в рамках старой неэффективной системы разработки.

*Совет*: Не все ‘камни’ достаточно большие, чтобы быть замеченными сразу. Путь бережливого подхода---и путь Скрам---заключается в том, чтобы *начать с больших камней* которые наиболее болезненны однако, по всей видимости, подвержены устранению и со временем уже работать с меньшими препятствиями.

Эта диаграмма причинно-следственной связи (нотация диаграммы объясняется в  ["Системном Мышлении"](./systems_thinking.html)) иллюстрирует эффект камней на дне озера в терминах модели системной динамики:

<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-11.png" alt="queueing-11.png">
  <figcaption>Косвенные преимущества и последующие отложенные выгоды уменьшения размера партий и времени цикла.</figcaption>
</figure>










## Применение Управления Очередями в LeSS

Существуют десятки стратегий для управления Очередями. ["Managing the Design Factory"](http://www.amazon.com/Managing-Design-Factory-Donald-Reinertsen/dp/0684839911/ref=sr_1_1?ie=UTF8&qid=1413688897&sr=8-1&keywords=managing+the+design+factory)  Дональда Рейнертсена рассказывает о многих из них. Однако, в контексте LeSS мы хотели бы сфокусироваться на нескольких ключевых шагах:

1. измените саму систему чтобы полностью ликвидировать очереди
2. научитесь обнаруживать оставшиеся очереди с помощью визуального управления
3. уменьшайте вариативность
4. ограничивайте размер очереди

*Измените систему*{: style="color: #1997C0"}---Должны ли вы управлять *существующими* очередями? Шагните за границы привычного мышления. Например, фича-команды, приёмочное TDD, непрерывная поставка - всё это помогает избавиться от многих очередей в традиционной разработке.

*Уменьшайте вариативность*{: style="color: #1997C0"}---Некоторые люди сначала пытаются уменьшить рабочие очереди через увеличение утилизации или многозадачность (с отрицательным результатом), или добавляя больше разработчиков. Действительно, добавление людей---если они талантливы---может помочь (за некоторыми исключениями), но это дорого и требует времени. Люди, которые достаточно понимают управление очередями, осознали более простую отправную точку: Уменьшайте [вариативность особого характера](https://en.wikipedia.org/wiki/Common_cause_and_special_cause_(statistics)), которая включает в себя сокращение размера партии.

Можно представить Бэклог Продукта как некую большую почти бесконечную приоритизированную очередь, но мы рекомендуем более детальный взгляд. Он имеет различные подмножества. Согласно одной точке зрения он содержит два подмножества: (1) список элементов, входящих в текущий релиз (который в идеале должен быть каждый Спринт), и (2)  “будущий бэклог”. Другой взгляд заключается в том, что Бэклог Продукта содержит два следующих подмножества:

**ясное-очищенное* подмножество из элементов, которые детально проанализированы, хорошо оценены, прекрасно раздроблены и сбалансированы так, чтобы их можно было сделать за гораздо меньшее время, чем длится Спринт для одной команды
* *нечёткое-грубое* подмножество крупно-дроблёных элементов разного размера нуждающихся в более детальном анализе, оценке и разделении на более мелкие, для того чтобы попасть в "ясное-очищенное" подмножество

Подмножества "текущий релиз" и "будущий бэклог" оба могут содержать ясные-очищенные и нечёткие-грубые элементы. В начале цикла релиза , "текущий релиз" как правило содержит, в основном, нечёткие-грубые элементы, и Спринт за Спринтом они уточняются, пока не станут ясными-очищенными, а затем реализованными.

Это подводит к некоторым ключевым моментам:

* В LeSS принято---и рекомендуется---приоритизировать только ясное-очищенное подмножество "текущего релиза".
* В LeSS, такая “ясная-очищенная приоритизированная очередь” является критически важной очередью работы, стоящей перед командами.
* Нечёткое-грубое подмножество является некой *очередью подачи* элементов в процесс Уточнения Бэклога Продукта, который добавляет высококачественные небольшие элементы в ясное-очищенное подмножество.

<figure>
  <img class="rounded shadowed" src="/img/queueing_theory/queueing-12.png" alt="queueing-12.png">
  <figcaption>Бэклог Продукта содержит несколько очередей.</figcaption>
</figure>



Прежде чем чересчур увлечься идеей уменьшения вариативости...соверменная разработка программного обеспечения не является промышленным производством; без вариаций ничего *нового* не происходит или не открывается. Существование вариативности в исследованиях и разработке как свойственно так и неизбежно. Однако действительно, есть некоторые виды изменчивости которые могут быть снижены---тема текущей главы. В терминологии Эдварда Деминга существует **вариативность (вариабельность) общего характера** и **вариативность особого (специального) характера**. Первая категория  - это вариация *общего шума* (системные отклонения, прим. переводчика) присущие самому процессу, связь которой с каким-либо специфичным (внешним) случаем сложно определить. С другой стороны, вариабельность особого характера (случайные внешние вмешательства, прим. переводчика)---также известная как **определяемая вариабельность**---может быть идентифицирована. Например, *вариативность размера запроса на новую функциональность* является вариативностью особого характера. А также *работа с плохо проанализированными, нечёткими требованиями* - это тоже вариативность особого характера. Путём сокращения поддающейся идентификации вариативности особого характера---в LeSS или в рабочих процессах---в системе с очередями улучшается средняя пропускная способность.

*Вариативность* является одним из трёх источников потерь в бережливом мышлении (оставшиеся два - это *перегрузка* и *не-приносящие-ценности действия* ). Понимание теории массового обслуживания помогает прояснить, почему вариативность расценивается как источник потерь.

Каковы некоторые источники и качества вариативности в LeSS?

* большие партии и большие элементы
* неоднозначность понимания элементов
* неоднозначность в том как спроектировать/реализовать элементы
* различающиеся затраты (оценка) для разных элементов
* количество элементов в ясной-очищенной приоритизированной очереди "текущий релиз"
* различие между ожидаемыми и фактическими затратами, которое может быть следствием неоднозначности что/как, неумелой оценки, обучения и прочего
* скорость поступления элементов в ясную-очищенную приоритизированную очередь текущего релиза
* вариативность команды и её отдельных членов
* перегрузка или отказ разделяемых ресурсов, таких как тестовая лаборатория и т.п.
{: .two_columns .box_top_bottom }

... и тому подобное (список не полон). В терминологии моделирования очередей, все они обычно сводятся к вариативности на уровне *обслуживания* или *скорости поступления*.

В бережливом мышлении, *поток* является ключевым принципом---и поток требует уменьшения или устранения вариативности. Вот почему  *балансировка* (выравнивание) также является и принципом бережливого подхода; это антидот для вариативности и помогает двигаться в направлении потока.



### Уменьшение Вариабельности Особого-Характера в LeSS

Вышесказанное приводит к некоторым советам по уменьшению вариабельности специального характера в LeSS:

**Уменьшайте вариативность с помощью небольшой очереди (играющей роль буфера) ясных-очищенных пользовательских историй в Бэклоге Релиза, примерно одинакового размера**{: style="color: #1997C0"}---В Toyota, небольшой буфер высоко-качественных запасов деталей используется, чтобы сгладить или выровнять передачу работы в последующий связанный процесс. Эти запасы (являющиеся временно необходимыми потерями) поддерживают *сбалансированное вытягивание* потому, что продуктовые команды LeSS теперь имеют очередь элементов для работы, примерно одинакового размера; никаких ожиданий и меньше неожиданностей. Элемент в нечётком-грубом подмножестве текущего релиза имеет высокую  *неоднозначность что/как* и довольно крупный; поэтому выбор его для реализации - это непрофессионально, так как увеличивает вариативность.

**Уменьшайте вариативность, проводя совместную сессию по Уточнение Бэклога Продукта (PBR) каждый Спринт**{: style="color: #1997C0"}--В LeSS, каждый спринт должен включать PBR для уточнения элементов таким образом они становятся готовыми для будущих Спринтов. Это уменьшает неоднозначность или вариативность что/как, а также уменьшает вариативность в оценке, потому что переоценка может улучшаться по мере того как люди учатся. На протяжении этой активности разбивайте элементы *на небольшие и примерно одинаковые*. Это сокращает размер партии и сопутствующую ему вариативность. Это также сокращает *пакетную задержку*---искусственная задержка важной под-функциональности потому, что она застряла в большей партии функциональности, часть которой является менее важной. Эти повторяющиеся сессии совместной работы также создают *регулярную каденцию* по добавлению ясных-очищенных элементов в очередь, уменьшая вариативность в скорости поступления.

**Уменьшайте вариативность благодаря стабильным продуктовым командам**{: style="color: #1997C0"}---Используйте стабилизировавшиеся, работающие совместно на протяжении долгого времени продуктовые команды в LeSS, чтобы уменьшить вариативность на уровне ‘обслуживания’---в командах. Также, кросс-функциональные, кросс-компонентные продуктовые команды увеличивают параллелизм и улучшают поток потому, что элемент может быть передан в любую из нескольких доступных команд.

**Уменьшайте вариативность с помощью ограниченных по времени и затратам исследовательских задач**{: style="color: #1997C0"}---Этот совет наиболее пригоден в областях с крупными *исследовательски-ориентированными* требованиями. Это уменьшает *неоднозначность что/как* и вариативность. Иногда нетривиальное исследование необходимо для того, чтобы только *начать* понимать исследуемую тему. Например, однажды мы занимались консультацией в офисе у заказчика в Будапеште; группа продукта мобильных телекоммуникаций хотела предоставлять “конференц-вызовы через сотовую связь.” Документация по международному стандарту в этой области насчитывает *тысячи* страниц. Чтобы только поверхностно понять эту тему , требуются колоссальные усилия. Один из подходов - это попросить команду “изучить предметную область.” Однако это работа, не имеющая чётких границ, способная привнести больше вариативности в обслуживании и может привести к потерям, которые в бережливом подходе классифицируются как переработка. Алтернативный подход---то, что рекомендуется в  LeSS---предложить команде ограниченную по времени и по затратам цель для изучения. Возможно, конкретной целью могло бы быть предоставление отчёта об исследовании в конце Спринта, вдобавок к работе по реализации элементов Бэклога. Например, “*подготовить вводный доклад про конференц-связь, за максимум 30 человеко-часов* .” Некое ограниченное количество  затрат отводится на исследование и изучение, сбалансированное с некоторым количеством реализуемых командой элементов. Затем Владелец Продукта мог бы принять решение инвестировать ещё некоторое количество ограниченных усилий в следующий цикл исследований в будущем Спринте (вероятно уже более сфокусированных по мере прояснения предмета исследований), до тех пор пока предмет не был бы окончательно понятен для людей в достаточной степени, чтобы начать формировать, разделять и оценивать элементы Бэклога.


### Reducing Queue Sizes in LeSS

Another queue-management technique is to limit queue size. This does not necessarily reduce variability, but it has other virtues. In a traditional development first-in first-out (FIFO) WIP queue, a *long* queue is a problem because it will take forever for an item to move forward through the queue and eventually be finished---a straightforward reason to limit FIFO WIP queue size.

That problem is less pernicious in a Product Backlog *priority queue*, since it can be re-sorted---something just added can move to the head of the list. Still, there are good reasons to limit the number of items in the clear-fine priority queue of the current release:

* A long list of fine-grained complex features is hard to understand and prioritize. In large-product development, we regularly hear complaints from the Product Owner that the backlog is too big for them to “get their head around.”
* A big backlog of clearly analyzed, finely split and well-estimated items has usually had some investment in it, proportional to its size. It is WIP with no return on that investment. As always with WIP or inventory, that is a financial risk.
* People forget details over time. All the items in the clear-fine subset have been through in-depth analysis in Product Backlog Refinement workshops. If that list is short, there is a good chance that the team implementing the item has *recently* analyzed it in a workshop, perhaps within the last two months. If the queue is very long and growing, there is a greater chance the team will take on an item analyzed long ago. Even though there will probably be written documentation that was generated long ago in the workshop, it will of course be imperfect, and their grasp of the details will be hazy and stale.

## Conclusion

Queue management can become a *hammer* so that you go looking for queue *nails* . Resist the temptation to manage existing queues---that is an inside-the-box response to the problem. Rather, consider doing *system kaizen* so that the underlying system is changed in some way so that queues can no longer form or exist. Parallelizing with cross-functional teams and acceptance test-driven development are common examples, but there are more. Only apply queue management---a *point kaizen* tactic---when you cannot eradicate a queue.

## Recommended Readings

There are dozens, if not hundreds, of general texts on queueing theory. More specifically, we suggest readings that make the connection between this subject and product development:

* [Managing the Design Factory](http://www.amazon.com/Managing-Design-Factory-Donald-Reinertsen/dp/0684839911/ref=sr_1_1?ie=UTF8&qid=1413691933&sr=8-1&keywords=managing+the+design+factory) by Don Reinertsen is a classic introduction on queueing theory and product development.

* [Flexible Product Development](http://www.amazon.com/Flexible-Product-Development-Building-Changing/dp/0787995843/ref=sr_1_1?ie=UTF8&qid=1413691975&sr=8-1&keywords=flexible+product+development) by Preston Smith was the first widely-popular general product development book that introduced agile software development concepts---including Scrum and Extreme Programming---to a broader audience. This text includes an analysis of queueing theory and variability, and their relationship to development.
